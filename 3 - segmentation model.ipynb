{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Seja o conjunto de dados disponibilizado na pasta Questão 3 (imagens e anotações em arquivo .json associado à construções, sobre imagens satelitais), implemente algum modelo responsável pela segmentação das residências presentes as imagens satelitais disponibilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import MeanIoU, Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar os dados e as anotações\n",
    "def load_data(image_folder, annotation_file_1, annotation_file_2):\n",
    "    images = []\n",
    "    annotations_1 = []\n",
    "    annotations_2 = []\n",
    "\n",
    "    # Carregar imagens da pasta\n",
    "    for filename in os.listdir(image_folder):\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "        if img_path.endswith(\".jpg\"):\n",
    "            img = Image.open(img_path)\n",
    "            images.append(img)\n",
    "\n",
    "    # Carregar anotações dos arquivos\n",
    "    with open(annotation_file_1, 'r') as file:\n",
    "        data_1 = json.load(file)\n",
    "        annotations_1 = data_1[\"annotations\"]\n",
    "\n",
    "    with open(annotation_file_2, 'r') as file:\n",
    "        data_2 = json.load(file)\n",
    "        annotations_2 = data_2[\"annotations\"]\n",
    "\n",
    "    # Combinar as anotações\n",
    "    combined_annotations = []\n",
    "    for annot_1, annot_2 in zip(annotations_1, annotations_2):\n",
    "        combined_annotation = np.logical_or(annot_1, annot_2)\n",
    "        combined_annotations.append(combined_annotation)\n",
    "\n",
    "    return np.array(images), np.array(combined_annotations)\n",
    "\n",
    "# Carregar dados e anotações\n",
    "image_folder = \"../ex3/building/train/images/\"\n",
    "annotation_file_1 = \"../ex3/building/annotation-small.json\"\n",
    "annotation_file_2 = \"../ex3/building/annotation.json\"\n",
    "X, y = load_data(image_folder, annotation_file_1, annotation_file_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir dados em conjuntos de treinamento e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Definir a arquitetura da rede neural\n",
    "def create_model(activation='relu', optimizer='adam'):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation=activation, padding='same', input_shape=(img_height, img_width, 3)),\n",
    "        MaxPooling2D((2, 2), padding='same'),\n",
    "        Conv2D(64, (3, 3), activation=activation, padding='same'),\n",
    "        MaxPooling2D((2, 2), padding='same'),\n",
    "        Conv2D(128, (3, 3), activation=activation, padding='same'),\n",
    "        MaxPooling2D((2, 2), padding='same'),\n",
    "        Conv2D(256, (3, 3), activation=activation, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(128, (3, 3), activation=activation, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation=activation, padding='same'),\n",
    "        UpSampling2D((2, 2)),\n",
    "        Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "    ])\n",
    "    model.compile(optimizer=optimizer, loss=BinaryCrossentropy(), metrics=[MeanIoU(num_classes=2), Precision(), Recall()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir hiperparâmetros para grid search\n",
    "param_grid = {\n",
    "    'activation': ['relu', 'elu'],\n",
    "    'optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "# Criar o modelo Keras para grid search\n",
    "model = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_model, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "# Realizar busca em grade\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, verbose=2)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Melhores parâmetros encontrados\n",
    "best_params = grid_result.best_params_\n",
    "print(\"Melhores Parâmetros:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Carregar dados\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m images, annotations \u001b[38;5;241m=\u001b[39m \u001b[43mload_data_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Pré-processamento\u001b[39;00m\n\u001b[1;32m      5\u001b[0m images \u001b[38;5;241m=\u001b[39m preprocess_images(images)\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mload_data_from_json\u001b[0;34m(json_file)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data_from_json\u001b[39m(json_file):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      4\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mannotations\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/FIESC/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.json'"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo com os melhores parâmetros\n",
    "best_model = create_model(activation=best_params['activation'], optimizer=best_params['optimizer'])\n",
    "history = best_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Avaliar o modelo com métricas diferentes\n",
    "loss, mean_iou, precision, recall = best_model.evaluate(X_test, y_test)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"Mean IoU:\", mean_iou)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FIESC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
